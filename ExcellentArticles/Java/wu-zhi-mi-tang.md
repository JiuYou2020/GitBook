---
description: My honey, your poison!
---

# 吾之蜜糖

## 基础

### **equals与hashCode**

**关联和约定**

1. **哈希表的使用：** 在 Java 中，哈希表（如 `HashMap`、`HashSet` 等）是基于哈希算法实现的数据结构，它通过哈希码（hash code）来快速定位对象的存储位置。
2. **约定一：相等对象必须具有相等的哈希码：** 如果两个对象根据 `equals()` 方法判断相等（即 `obj1.equals(obj2)` 返回 `true`），那么这两个对象的哈希码必须相等（即 `obj1.hashCode() == obj2.hashCode()`）。
3. **约定二：不相等的对象尽量有不同的哈希码：** 如果两个对象根据 `equals()` 方法判断不相等，不要求它们的哈希码一定不相等，但是为了提高哈希表的性能，不相等的对象尽量有不同的哈希码，减少哈希冲突。

**为什么需要重写 `hashCode()` 方法？**

* **保证哈希表性能：** 如果重写了 `equals()` 方法，但没有重写 `hashCode()` 方法，那么两个根据 `equals()` 判断相等的对象可能会有不同的哈希码，这违反了约定一，会导致这两个对象在哈希表中无法正确被处理，甚至无法通过 `HashMap` 或 `HashSet` 正确地进行存储和检索。
* **确保对象一致性：** 重写 `hashCode()` 方法可以保证根据 `equals()` 方法判断相等的对象拥有相等的哈希码，从而在使用哈希表时能够正确地识别和处理相等的对象。

### 抽象类和接口有什么区别？

1. **成员方法实现：**
   * **抽象类：** 可以包含普通方法的实现，也可以包含抽象方法（没有具体实现，只有方法声明）。抽象类中的非抽象方法可以提供默认实现，子类可以选择性地覆盖这些方法。
   * **接口：** 只能包含抽象方法的声明，不包含方法的实现。在 Java 8 及以后的版本中，接口可以包含默认方法和静态方法的实现。
2. **多继承：**
   * **抽象类：** Java 中的类只能单继承，因此抽象类只能继承一个具体类或抽象类。但是抽象类可以实现多个接口。
   * **接口：** 接口支持多继承，一个类可以实现多个接口，从而实现多重继承的效果。
3. **构造方法：**
   * **抽象类：** 可以有构造方法，并且抽象类的构造方法在子类实例化时会被调用。
   * **接口：** 不允许有构造方法，接口中不能定义实例字段，因为接口中的方法都是抽象的，没有实例变量可以初始化。
4. **用途和设计：**
   * **抽象类：** 是对类的一种抽象，是一种模版设计。
   * **接口：** 用于定义一种能力或行为，描述了一种规范或契约，实现接口的类需要提供接口中定义的所有方法的具体实现。接口适合用于不同类之间的行为规范和统一的契约。

### Class#forName 和 ClassLoader 区别

* `Class#forName(...)` 方法，除了将类的 `.class` 文件加载到JVM 中之外，还会对类进行解释，执行类中的 `static` 块。
* ClassLoader 只干一件事情，就是将 `.class` 文件加载到 JVM 中，不会执行 `static` 中的内容，只有在 newInstance 才会去执行 `static` 块。

## 集合

### 快速失败（fail-fast）和安全失败（fail-safe）的区别

* 快速失败：当你在迭代一个集合的时候，如果有另一个线程正在修改你正在访问的那个集合时，就会抛出一个 ConcurrentModification 异常。 在 `java.util` 包下的都是快速失败。
* 安全失败：你在迭代的时候会去底层集合做一个拷贝，所以你在修改上层集合的时候是不会受影响的，不会抛出 ConcurrentModification 异常。在 `java.util.concurrent` 包下的全是安全失败的。

### Comparable 和 Comparator 的区别?

* Comparable 接口，在 `java.lang` 包下，用于当前对象和其它对象的比较，所以它有一个 `#compareTo(Object obj)` 方法用来排序，该方法只有一个参数。
* Comparator 接口，在 `java.util` 包下，用于传入的两个对象的比较，所以它有一个 `#compare(Object obj1, Object obj2)` 方法用来排序，该方法有两个参数。

### ArrayList 与 LinkedList 区别？

**ArrayList**

* 优点：ArrayList 是实现了基于动态数组的数据结构，因为地址连续，一旦数据存储好了，查询操作效率会比较高（在内存里是连着放的）。
* 缺点：因为地址连续，ArrayList 要移动数据，所以插入和删除操作效率比较低。

**LinkedList**

* 优点：LinkedList 基于链表的数据结构，地址是任意的，所以在开辟内存空间的时候不需要等一个连续的地址。对于新增和删除操作 add 和 remove ，LinedList 比较占优势。LinkedList 适用于要头尾操作或插入指定位置的场景。
* 缺点：因为 LinkedList 要移动指针，所以查询操作性能比较低。

### ArrayList 是如何扩容

* 如果通过无参构造的话，初始数组容量为 0 ，当真正对数组进行添加时，才真正分配容量。每次按照 **1.5** 倍（位运算）的比率通过 copeOf 的方式扩容。
* 在 JKD6 中实现是，如果通过无参构造的话，初始数组容量为10，每次通过 copeOf 的方式扩容后容量为原来的 **1.5** 倍。

### HashMap 和 Hashtable 的区别

**线程安全性**

* **Hashtable：** 是线程安全的类，它的方法都是同步的（synchronized），多个线程可以安全地访问一个 `Hashtable` 实例，但这也导致在多线程环境下性能相对较低。
* **HashMap：** 是非线程安全的类，它的方法没有进行同步处理，因此多个线程同时访问 `HashMap` 可能导致数据不一致或其他问题。若需要在多线程环境下使用 `HashMap`，可以通过 `Collections.synchronizedMap()` 方法来创建同步的 `HashMap`。

**Null 键和值的处理**

* **Hashtable：** 不允许使用 null 作为键或值，否则会抛出 `NullPointerException`。
* **HashMap：** 允许使用 null 作为键和值，即 `HashMap` 中可以存储键或值为 null 的条目。

**性能**

* **HashMap：** 由于 `HashMap` 非线程安全，不进行同步处理，因此在单线程环境下性能较高。
* **Hashtable：** 由于 `Hashtable` 所有方法都进行了同步处理，因此在多线程环境下保证了线程安全，但性能相对较低。

**现状**

* **Hashtable：** 继承自 `Dictionary` 类，已经被淘汰（Deprecated）。
* **HashMap：** 实现了 `Map` 接口，是 `AbstractMap` 的子类，属于 Java Collections Framework 的一部分。

**初始容量和扩容机制**

* HashTable 中数组默认大小是 11 ，扩容方法是 `old * 2 + 1` ，HashMap 默认大小是 16 ，扩容每次为 2 的指数大小。

### HashMap 和 ConcurrentHashMap区别

1. **内部结构**：在JDK1.8之前，ConcurrentHashMap使用分段锁（Segmentation）来提供并发性。每个段本质上是一个独立的HashMap，并且拥有一个锁。在JDK1.8之后，Segmentation被移除了。ConcurrentHashMap采用了一种不同的锁机制（synchronized和CAS操作）来提高并发性。
   * 当数组中当前位置为空时，使用CAS来把新的节点写入数组中对应的位置。
   * 当数组中当前位置不为空时，通过加锁（synchronized）来添加或删除节点。如果当前位置是链表，就遍历链表找到合适的位置插入或删除节点。如果当前位置是红黑树，就按照红黑树的规则插入或删除节点。
   * 当链表长度超过阈值（默认为8）时，就把链表转换为红黑树。当红黑树节点数小于阈值（默认为6）时，就把红黑树转换为链表。
2. **线程安全**：HashMap非线程安全，不能保证在多线程环境下的共享访问，而ConcurrentHashMap是线程安全的，设计用于多线程的环境中。
3. **性能**：由于ConcurrentHashMap的线程安全特性，它在多线程环境下比HashMap有更好的性能。它通过使用复杂的锁策略和CAS操作来最小化锁的竞争。
4. **内存一致性**：ConcurrentHashMap的读操作可以不加锁，并且其写操作可以延迟更新到主存，不同步其他读写操作，而HashMap在多线程下使用时需要外部同步。

`HashMap` 是 Java 中常用的哈希表实现的数据结构，用于存储键值对。在理解 `HashMap` 的工作原理和在 JDK 1.8 之后向其中添加元素可能发生的情况之前，我们先来了解 `HashMap` 的基本原理和核心概念。

### HashMap 的工作原理

1. **哈希表数组：** `HashMap` 内部维护一个数组，数组的每个元素称为桶（bucket）。桶是存放键值对的基本单元，每个桶可能存放一个链表或红黑树，用来解决哈希冲突（即多个键映射到同一个桶的情况）。
2. **哈希函数：** 当向 `HashMap` 中添加键值对时，首先会根据键的 `hashCode()` 方法计算哈希值，然后通过哈希函数确定键值对应该存放在数组的哪个桶中。
3. **解决哈希冲突：** 如果多个键的哈希值映射到同一个桶中（即发生哈希冲突），`HashMap` 使用链表或红黑树来存储这些键值对。链表用于简单的存储，而当链表长度超过一定阈值（默认为8），链表会转换为红黑树，提高查找效率。

### JDK 1.8 向 HashMap 添加元素可能发生的情况

在 JDK 1.8 中，向 `HashMap` 添加元素时可能会触发以下情况：

1. **计算哈希值：** 根据新加入键的 `hashCode()` 方法计算哈希值。
2. **确定存放位置：** 根据哈希值和当前数组的长度计算键值对应该存放在数组的哪个桶中（hashCode & capacity）。使用&而不是%是因为&的计算效率更高，这也是为什么hashMap扩容后是2的n次幂。
3. **桶为空或非空处理：**
   * 如果目标桶为空（即没有发生哈希冲突），直接将新的键值对存放在该桶中。
   * 如果目标桶已经有其他键值对：
     * 如果目标桶中的元素为链表，将新的键值对追加到链表的末尾。
       * 如果链表的长度超过8，如果桶数组的长度超过64则将链表修改为红黑树。
       * 如果链表的长度超过8，如果桶数组的长度没有超过64则出发扩容操作。
     * 如果目标桶中的元素为红黑树，按照红黑树的规则插入新的键值对。
4. **链表转红黑树：**
   * 当向一个桶中添加元素时，如果该桶中链表长度达到阈值（默认为8），会将链表转换为红黑树，提高查找效率。
5.  **扩容：** 如果添加元素后 `HashMap` 中的元素数量达到数组容量的阈值（负载因子，默认为0.75），会触发扩容操作。扩容会将数组容量增加一倍，并重新计算每个键值对的存放位置。

    ```java
    int index = hash(key) & (newCapacity - 1);
    ```
    
    



## 并发

### 简述线程、进程、程序的基本概念？

**程序**

程序，是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。

**进程**

进程，是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，它在计算机中一个指令接着一个指令地执行着，同时，每个进程还占有某些系统资源如CPU时间，内存空间，文件，文件，输入输出设备的使用权等等。换句话说，当程序在执行时，将会被操作系统载入内存中。

**线程**

线程，与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

### 你了解守护线程吗？它和非守护线程有什么区别？

Java 中的线程分为两种：守护线程（Daemon）和用户线程（User）。

守护线程一般由JVM自动创建，也可以通过Thread#setDaemon(boolean on)方法进行手动设置。

当用户线程执行完毕，只剩下守护线程时，JVM会自动退出。

### 什么是线程饥饿？

饥饿，一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。

Java 中导致饥饿的原因：

* 高优先级线程吞噬所有的低优先级线程的 CPU 时间。
* 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。
* 线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的 wait 方法)，因为其他线程总是被持续地获得唤醒。

### 线程的五状态与七状态模型

![Thread 的线程状态](https://raw.githubusercontent.com/JiuYou2020/GitBook/master/ExcellentArticles/Java/.gitbook/assets/5eeec5f68f4fc412246efd4111d6fdec.png)

### 创建线程的方式

* 方式一，继承 Thread 类创建线程类。
* 方式二，通过 Runnable 接口创建线程类。
* 方式三，通过 Callable 接口和 Future 创建线程。
* 方式四，通过线程池创建线程。

### 一个线程运行时发生异常会怎样？

如果异常没有被捕获该线程将会停止执行。

`Thread.UncaughtExceptionHandler` 是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。

当一个未捕获异常将造成线程中断的时候 JVM 会使用 `Thread#getUncaughtExceptionHandler()` 方法来查询线程的 UncaughtExceptionHandler 并将线程和异常作为参数传递给 handler 的 `#uncaughtException(exception)` 方法进行处理。

### Thread#sleep()与Object#wait()区别

* sleep 方法，是线程类 Thread 的静态方法。调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复（线程回到就绪状态）
* wait 方法，是 Object 类的方法。调用对象的 `#wait()` 方法，会导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的 `#notify()` 方法（或`#notifyAll()`方法）时，才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。

### 为什么 wait 和 notify 方法要在同步块中调用？

* Java API 强制要求这样做，如果你不这么做，你的代码会抛出 IllegalMonitorStateException 异常。
* wait和notify是用于线程间进行通信的，显然两线程通信过程中让其他线程横叉一脚是不合适的。

### 为什么你应该在循环中检查等待条件

处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。

```java
// The standard idiom for using the wait method
synchronized (obj) {
    while (condition does not hold) {
        obj.wait(); // (Releases lock, and reacquires on wakeup)
    }
    ... // Perform action appropriate to condition
}
```

### sleep(0) 有什么用途？

`Thread#sleep(0)` 方法，并非是真的要线程挂起 0 毫秒，意义在于这次调用 `Thread#sleep(0)` 方法，把当前线程确实的被冻结了一下，让其他线程有机会优先执行。`Thread#sleep(0)` 方法，是你的线程暂时放弃 CPU ，也就是释放一些未用的时间片给其他线程或进程使用，就相当于一个**让位动作**。

### 单例模式的线程安全性?

* 饿汉式单例模式的写法：线程安全
* 懒汉式单例模式的写法：非线程安全
* 双检锁单例模式的写法：线程安全



### synchronized的实现原理与应用

总结：

1. 可以被修饰的对象有哪些？
2. 对象头中存储的内容？
3. 锁有几种状态？
4. 锁如何升级？
5. 在轻量级锁和重量级锁中，会将对象头中原来的内容存放到哪里？

参考链接：

https://app.gitbook.com/o/kCU9nigbAxy9O5ghLetb/s/4nPAqAgKpdmjLNSFVzrX/java-bing-fa-de-yi-shu#synchronized-de-shi-xian-yuan-li-yu-ying-yong

推荐阅读：

《Java并发编程的艺术》第二章 第2节

https://weread.qq.com/web/reader/a1b42863643425f316430426755426757427657366e61366f5642696438626160ckaab325601eaab3238922e53?

### 同步方法和同步块，哪个是更好的选择

同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。

同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。



### 关于volatile你应该知道的事

总结：

volatile在两个方面发挥作用

1. **以volatile修饰变量保证变量的内存可见性**
2. **以volatile修饰变量防止内存重排序**

上述两点都与volatile底层的**内存屏障**有关，一条指令序列从编译到依次执行会经过三次重排序：

1. **编译器优化重排序**。在不改变单线程语义的前提下，可以重新安排语句的执行顺序，也就是说遵从`as if serial`规则。
2. **处理器指令集并行重排序**。处理器采用指令级并行技术将多条指令重叠执行。
3. **内存系统重排序**。与处理器使用缓存和读/写缓冲区有关。

正是由于处理器会使用缓存和读/写缓冲区，导致了多线程对同一共享变量读取的并发问题（即JMM中的工作内存和主内存），而volatile使用内存屏障来解决这个问题，volatile插入内存屏障的规则如下：

- 在volatile写前插入`StoreStore`内存屏障，使得写之前的所有写指令的结果对本次写可见（底层是使工作内存保存的副本无效）。
- 在volatile写后插入`StoreLoad`屏障，使得本次写的结果对之后的读指令可见。
- 在volatile读后插入一个`LoadLoad`屏障，确保本次数据的装载先于后续指令数据的装载。
- 在volatile读后插入一个`LoadStore`屏障，确保本次数据装载先于后续存储指令刷新到内存。

上面的内存屏障，既可以保证内存可见性，也可以防止指令重排序。

详细总结：

https://app.gitbook.com/o/kCU9nigbAxy9O5ghLetb/s/4nPAqAgKpdmjLNSFVzrX/java-bing-fa-de-yi-shu#huan-cun-yi-zhi-xing

推荐阅读：

《Java并发编程的艺术》第三章 第4节

> ps：更推荐阅读第三章的全部内容，虽然有些内容可能已经过时，但是还是会称赞设计者的奇思妙想~
>
> ps：比我写的好多了！

https://weread.qq.com/web/reader/a1b42863643425f316430426755426757427657366e61366f5642696438626160ck1c3321802231c383cd30bb3?



### 可以创建 `volatile` 数组吗?

结论：使用 `volatile` 修饰数组或对象引用可以确保对引用的写入操作对其他线程是可见的，但并不能保证引用指向的对象或数组内部的状态的可见性和一致性。如果需要保证数组或对象内部的状态在多线程环境中的可见性和一致性，需要考虑使用其他并发工具或技术，例如锁（`synchronized`）、并发集合类（如 `ConcurrentHashMap`、`CopyOnWriteArrayList` 等）、`Atomic` 类等

Java 中可以创建 `volatile` 类型数组，不过只是一个指向数组的引用，而不是整个数组。如果改变引用指向的数组（即将该引用指向一个新数组），将会受到 `volatile` 的保护，但是如果多个线程同时改变数组的元素，`volatile` 标示符就不能起到之前的保护作用了。

同理，对于 Java POJO 类，使用 `volatile` 修饰，只能保证这个引用的可见性，不能保证其内部的属性。



### long和double型变量的读写是否存在并发问题

在32位操作系统中存在并发问题，推荐使用volatile修饰。

32位操作系统的总线只有32位，而double和long类型的数据是64位，可能A线程刚将数据存放至寄存器的高32位，低32位还没有存放，B线程就开始读取该线程。



### `volatile` 和 `synchronized` 的异同？

推荐先阅读[关于volatile你应该知道的事](#关于volatile你应该知道的事)

1. **原理不同**：volatile的底层原理是通过插入内存屏障与`happens before`规则来保证多线程之间的内存可见性与防止指令重排，工作在虚拟机和处理器级别。而Synchronize关键字的底层原理是通过对`Mark word`（对象头）的操作来实现多线程之间的同步，工作在虚拟机级别。

2. **关键字修饰的内容不同**：volatile修饰变量，Synchronize修饰变量，方法，类。

3. **内存语义相同**：

   锁释放与volatile写有相同的内存语义。锁获取与volatile读有相同的内存语义。

   在线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。释放也与之类似。

   而当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。写一个volatile变量同理。

   由于他们的内存语义相同，因此对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。

4. **是否具有原子性**：Synchronize修饰的内容具有原子性，而对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。

5. **是否造成线程阻塞**：volatile不会，Synchronize会。



### 什么是 Java Lock 接口？

它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。

![image-20240415210310266](https://raw.githubusercontent.com/JiuYou2020/GitBook/master/ExcellentArticles/Java/.gitbook/assets/image-20240415210310266.png)



### 什么是AQS？

队列同步器AbstractQueuedSynchronizer，是用来构建锁或者其他同步组件的基础框架，它**使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作**。

锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域。

FIFO队列示意图：

![image-20240415213756194](https://raw.githubusercontent.com/JiuYou2020/GitBook/master/ExcellentArticles/Java/.gitbook/assets/image-20240415213756194.png)



独占式获取同步状态示意图：

![image-20240415213824758](https://raw.githubusercontent.com/JiuYou2020/GitBook/master/ExcellentArticles/Java/.gitbook/assets/image-20240415213824758.png)



在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。



推荐阅读：

《Java并发编程的艺术》第五章 第2节

https://weread.qq.com/web/reader/a1b42863643425f316430426755426757427657366e61366f5642696438626160cked332ca0262ed3d2c2191f2?



###  synchronized 和 ReentrantLock 异同？

- 相同点
  - 都实现了多线程同步和内存可见性语义。
  - 都是可重入锁。
- 不同点
  - 同步实现机制不同
    - `synchronized` 通过 Java 对象头锁标记和 Monitor 对象实现同步。
    - ReentrantLock 通过CAS、AQS（AbstractQueuedSynchronizer）实现同步。
  - 可见性实现机制不同,即不同线程对同一代码块中共享变量的可见性。
    - `synchronized` 依赖 JMM保证共享变量的多线程内存可见性。
      - ps：synchronize关键字是通过`happens before`规则来保证内存可见性的。当线程释放锁时，JMM会将本地内存中共享变量刷新到共享内存；获取锁时，会使本地内存中的共享变量无效化。
    - ReentrantLock 通过 AQS 的 `volatile state` 保证共享变量的多线程内存可见性。
      - ps：例如在公平锁中，释放锁时会写`volatile`变量state；在获取锁时会读state。而根据`volatile`的`happens before`规则，释放锁的线程写state变量之前的共享变量，在获取锁的线程读取同一个state变量后会立即变得对获取锁的线程可见。本质上也是`happens before`规则。
    - 两者的本质上是利用同一套方法来保证内存可见性的，即`happens before`规则插入内存屏障防止指令重排序，以及刷新内存。
      - ps：**如果实在不理解这一点，可以仔细阅读《Java并发编程的艺术》第三章内容**。
  - 使用方式不同
    - `synchronized` 可以修饰实例方法（锁住实例对象）、静态方法（锁住类对象）、代码块（显示指定锁对象）。
    - ReentrantLock 显示调用 tryLock 和 lock 方法（在try之前调用），需要在 `finally` 块中释放锁。
  - 功能丰富程度不同
    - `synchronized` 不可设置等待时间、不可被中断（interrupted）。
    - ReentrantLock 提供有限时间等候锁（设置过期时间）、可中断锁（lockInterruptibly），尝试非阻塞的获取锁、condition（提供 await、signal 等方法）等丰富功能
  - 锁类型不同
    - `synchronized` 只支持非公平锁。
    - ReentrantLock 提供公平锁和非公平锁实现。当然，在大部分情况下，非公平锁是高效的选择。



### 什么是JMM？

> 有些面试官会把java运行时数据区域和JMM混淆。。。（我就yudao过...）

JMM即Java内存模型，JMM决定一个线程对共享变量的写入何时对另一个线程可见。

关键词：工作内存，主内存，无效



### 什么是重排序？

为了提高性能，编译器和处理器会对指令序列进行重排序，排序的几种方式见[关于volatile你应该知道的事](#关于volatile你应该知道的事)

但是单线程环境中重排序不会改变程序运行的结果。

存在数据依赖关系的指令不允许重排序。例如`int a = 3; int b = a;`这样的指令序列。

### 什么是happens before？

结论：A happens before B即A指令序列的结果对B可见，但是A指令序列不一定要在B之前执行。

- as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。
- as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。
- happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。

推荐阅读：《Java并发编程的艺术》第三章 第1.5节 第7.2、7.3节

https://weread.qq.com/web/reader/a1b42863643425f316430426755426757427657366e61366f5642696438626160ck1ff325f02181ff1de7742fc?

https://weread.qq.com/web/reader/a1b42863643425f316430426755426757427657366e61366f5642696438626160ck9f6326602389f61408e3715?



### 什么是阻塞队列？

BlockingQueue 接口，是 Queue 的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性：

- 当生产者线程试图向 BlockingQueue 放入元素时，如果队列已满，则线程被阻塞。
- 当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞。
- 正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中 放入元素，取出元素，它可以很好的控制线程之间的通信。

阻塞队列使用最经典的场景，就是 Socket 客户端数据的读取和解析：

- 读取数据的线程不断将数据放入队列。
- 然后，解析线程不断从队列取数据解析。



### Java有哪些阻塞队列？

- 【最常用】ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。

  > 此队列按照先进先出（FIFO）的原则对元素进行排序，但是默认情况下不保证线程公平的访问队列，即如果队列满了，那么被阻塞在外面的线程对队列访问的顺序是不能保证线程公平（即先阻塞，先插入）的。

- LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。

  > 此队列按照先出先进的原则对元素进行排序

- PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。

- DelayQueue：支持延时获取元素的无界阻塞队列，即可以指定多久才能从队列中获取当前元素。

- SynchronousQueue：一个不存储元素的阻塞队列。

  > 每一个 put 必须等待一个 take 操作，否则不能继续添加元素。并且他支持公平访问队列。

- LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。

  > 相对于其他阻塞队列，多了 tryTransfer 和 transfer 方法。
  >
  > - transfer 方法：如果当前有消费者正在等待接收元素（take 或者待时间限制的 poll 方法），transfer 可以把生产者传入的元素立刻传给消费者。如果没有消费者等待接收元素，则将元素放在队列的 tail 节点，并等到该元素被消费者消费了才返回。
  > - tryTransfer 方法：用来试探生产者传入的元素能否直接传给消费者。如果没有消费者在等待，则返回 false 。和上述方法的区别是该方法无论消费者是否接收，方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。

- LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

  > 优势在于多线程入队时，减少一半的竞争。





### CAS操作有什么缺点？

1. ABA问题
2. 循环时间长开销大，当存在资源竞争时，CAS会发生自旋，浪费CPU资源
3. 只能保证一个共享变量的院子操作。























